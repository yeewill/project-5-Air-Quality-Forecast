{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQI to ppm ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aqi2ppm(aqi):\n",
    "    def new_scale(x, in_min, in_max, out_min,  out_max):\n",
    "        return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "    if (aqi<=50):\n",
    "        ozone = new_scale(aqi, in_min=0, in_max=50, out_max=54, out_min=0)\n",
    "    elif (aqi>50 and aqi<=100):\n",
    "        ozone = new_scale(aqi, in_min=51, in_max=100, out_max=70, out_min=55)\n",
    "    elif (aqi>100 and aqi<=150):\n",
    "        ozone = new_scale(aqi, in_min=101, in_max=150, out_max=85, out_min=71)\n",
    "    elif (aqi>150 and aqi<=200):\n",
    "        ozone = new_scale(aqi, in_min=151, in_max=200, out_max=105, out_min=86) \n",
    "    elif (aqi>200 and aqi<=300):\n",
    "        ozone = new_scale(aqi, in_min=200, in_max=300, out_max=200, out_min=106)\n",
    "    elif (aqi>300 and aqi<=500):\n",
    "        ozone = new_scale(aqi, in_min=301, in_max=500, out_max=600, out_min=201) \n",
    "    return (ozone/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull 7 days of Ozone and Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AIR NOW fo OZONE\n",
    "airnowkey = pickle.load(open('airnowAPIkey.p','rb'))\n",
    "\n",
    "sfcurrenturl='http://www.airnowapi.org/aq/observation/zipCode/current/?format=text/csv&zipCode=94117&distance=25&API_KEY='+airnowkey\n",
    "sf_ozone= pd.read_csv(sfcurrenturl)\n",
    "sf_today= aqi2ppm(sf_ozone[sf_ozone['ParameterName']=='O3'].loc[:,'AQI'][0])\n",
    "\n",
    "\n",
    "historical_ozone = [sf_today]\n",
    "for day in range(1,7):\n",
    "    year =str((datetime.today() -timedelta(days=day)).year)\n",
    "    month= str((datetime.today() -timedelta(days=day)).month)\n",
    "    day= str((datetime.today() -timedelta(days=day)).day)\n",
    "\n",
    "    url='http://www.airnowapi.org/aq/observation/zipCode/historical/?format=text/csv&zipCode=94117&date='+year+'-'+month+'-'+day+'T00-0000&distance=25&API_KEY='+airnowkey\n",
    "\n",
    "    raw=pd.read_csv(url)\n",
    "    value=aqi2ppm(raw[raw['ParameterName']=='OZONE'].loc[:,'AQI'][0])\n",
    "    historical_ozone.append(value)\n",
    "historical_ozone.reverse()\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "\n",
    "\n",
    "#Dark SKY for weather\n",
    "\n",
    "dskey = pickle.load(open(\"darkskyapi.p\",'rb'))\n",
    "\n",
    "\n",
    "\n",
    "day_length =[]\n",
    "temp_high =[]\n",
    "temp_low =[]\n",
    "dew_point =[]\n",
    "humidity =[]\n",
    "pressure =[]\n",
    "wind_speed =[]\n",
    "wind_bearing =[]\n",
    "cloud_cover =[]\n",
    "uv_index =[]\n",
    "date =[]\n",
    "\n",
    "for i in range(-5,7):\n",
    "    try:\n",
    "        long = 122.4482\n",
    "        lat = 37.7697\n",
    "        day = datetime.today() -timedelta(days=i)\n",
    "        day = int(time.mktime(day.timetuple()))\n",
    "        url ='https://api.darksky.net/forecast/'+dskey+'/'+str(lat)+','+str(long)+','+str(day)\n",
    "        weather= requests.get(url)\n",
    "        day_length.append(weather.json()['daily']['data'][0]['sunsetTime'] - weather.json()['daily']['data'][0]['sunriseTime'])\n",
    "        try:\n",
    "            temp_high.append(weather.json()['daily']['data'][0]['temperatureHigh'])\n",
    "        except:\n",
    "            temp_high.append(weather.json()['daily']['data'][0]['temperatureMax'])\n",
    "        try:\n",
    "            temp_low.append(weather.json()['daily']['data'][0]['temperatureLow'])\n",
    "        except:\n",
    "            temp_low.append(weather.json()['daily']['data'][0]['temperatureMin'])\n",
    "        dew_point.append(weather.json()['daily']['data'][0]['dewPoint'])\n",
    "        humidity.append(weather.json()['daily']['data'][0]['humidity'])\n",
    "        pressure.append(weather.json()['daily']['data'][0]['pressure'])\n",
    "        wind_speed.append(weather.json()['daily']['data'][0]['windSpeed'])\n",
    "        wind_bearing.append(weather.json()['daily']['data'][0]['windBearing'])\n",
    "        cloud_cover.append(weather.json()['daily']['data'][0]['cloudCover'])\n",
    "        uv_index.append(weather.json()['daily']['data'][0]['uvIndex'])\n",
    "        date.append(pd.to_datetime(weather.json()['daily']['data'][0]['time'],unit='s'))\n",
    "    except:\n",
    "        print('broken at: ' +str(i))\n",
    "day_length.reverse()\n",
    "temp_high.reverse()\n",
    "temp_low.reverse()\n",
    "dew_point.reverse()\n",
    "humidity.reverse()\n",
    "pressure.reverse()\n",
    "wind_speed.reverse()\n",
    "wind_bearing.reverse()\n",
    "cloud_cover.reverse()\n",
    "uv_index.reverse()\n",
    "date.reverse()\n",
    "\n",
    "df= pd.DataFrame({\n",
    "    'Ozone': historical_ozone,\n",
    "    'day_length' : day_length,\n",
    "    'temp_high' : temp_high,\n",
    "    'temp_low' : temp_low,\n",
    "    'dew_point' : dew_point,\n",
    "    'humidity' : humidity,\n",
    "    'pressure' : pressure,\n",
    "    'wind_speed' : wind_speed,\n",
    "    'wind_bearing' : wind_bearing,\n",
    "    'cloud_cover' : cloud_cover,\n",
    "    'uv_index' :uv_index\n",
    "    \n",
    "    \n",
    "})\n",
    "## load SF scaler\n",
    "scaler = pickle.load(open('scaler_all.p','rb'))\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "## load SF prediction scaler\n",
    "pred_scaler=pickle.load(open('pred_scaler.p','rb'))\n",
    "\n",
    "# load dataset\n",
    "values = df.values\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "values = df.astype('float32')\n",
    "# normalize features\n",
    "scaler = pickle.load(open('scaler_all.p','rb'))\n",
    "scaled = scaler.transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 7, 5)\n",
    "# drop columns we don't want to predict\n",
    "five_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)'], axis =1).values\n",
    "five_day = five_day.reshape((five_day.shape[0], 1, five_day.shape[1]))\n",
    "five_day_lstm = keras.models.load_model('models/multi5day.h5')\n",
    "\n",
    "sf_five = pred_scaler.inverse_transform(five_day_lstm.predict(five_day))[0][0]\n",
    "\n",
    "four_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "four_day = four_day.reshape((four_day.shape[0], 1, four_day.shape[1]))\n",
    "four_day_lstm = keras.models.load_model('models/multi4day.h5')\n",
    "\n",
    "sf_four = pred_scaler.inverse_transform(four_day_lstm.predict(four_day))[0][0]\n",
    "\n",
    "three_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                           'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "three_day = three_day.reshape((three_day.shape[0], 1, three_day.shape[1]))\n",
    "three_day_lstm = keras.models.load_model('models/multi3day.h5')\n",
    "\n",
    "sf_three = pred_scaler.inverse_transform(three_day_lstm.predict(three_day))[0][0]\n",
    "\n",
    "two_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                          'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)',\n",
    "                          'var2(t+2)','var3(t+2)','var4(t+2)','var5(t+2)','var6(t+2)',\n",
    "                          'var7(t+2)','var8(t+2)','var9(t+2)','var10(t+2)','var11(t+2)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "two_day = two_day.reshape((two_day.shape[0], 1, two_day.shape[1]))\n",
    "two_day_lstm = keras.models.load_model('models/multi2day.h5')\n",
    "\n",
    "sf_two = pred_scaler.inverse_transform(two_day_lstm.predict(two_day))[0][0]\n",
    "\n",
    "one_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                          'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)',\n",
    "                          'var2(t+2)','var3(t+2)','var4(t+2)','var5(t+2)','var6(t+2)',\n",
    "                          'var7(t+2)','var8(t+2)','var9(t+2)','var10(t+2)','var11(t+2)',\n",
    "                          'var2(t+1)','var3(t+1)','var4(t+1)','var5(t+1)','var6(t+1)',\n",
    "                          'var7(t+1)','var8(t+1)','var9(t+1)','var10(t+1)','var11(t+1)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "one_day = one_day.reshape((one_day.shape[0], 1, one_day.shape[1]))\n",
    "one_day_lstm = keras.models.load_model('models/multi1day.h5')\n",
    "\n",
    "sf_one = pred_scaler.inverse_transform(one_day_lstm.predict(one_day))[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "airnowkey = pickle.load(open('airnowAPIkey.p','rb'))\n",
    "\n",
    "lacurrenturl='http://www.airnowapi.org/aq/observation/zipCode/current/?format=text/csv&zipCode=91702&distance=25&API_KEY='+airnowkey\n",
    "la_ozone= pd.read_csv(lacurrenturl)\n",
    "la_today= aqi2ppm(la_ozone[la_ozone['ParameterName']=='O3'].loc[:,'AQI'][0])\n",
    "\n",
    "\n",
    "historical_ozone = [la_today]\n",
    "for day in range(1,7):\n",
    "    year =str((datetime.today() -timedelta(days=day)).year)\n",
    "    month= str((datetime.today() -timedelta(days=day)).month)\n",
    "    day= str((datetime.today() -timedelta(days=day)).day)\n",
    "\n",
    "    url='http://www.airnowapi.org/aq/observation/zipCode/historical/?format=text/csv&zipCode=91702&date='+year+'-'+month+'-'+day+'T00-0000&distance=25&API_KEY='+airnowkey\n",
    "\n",
    "    raw=pd.read_csv(url)\n",
    "    value=aqi2ppm(raw[raw['ParameterName']=='OZONE'].loc[:,'AQI'][0])\n",
    "    historical_ozone.append(value)\n",
    "historical_ozone.reverse()\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "historical_ozone.append(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dark SKY for weather\n",
    "\n",
    "dskey = pickle.load(open(\"darkskyapi.p\",'rb'))\n",
    "\n",
    "\n",
    "\n",
    "day_length =[]\n",
    "temp_high =[]\n",
    "temp_low =[]\n",
    "dew_point =[]\n",
    "humidity =[]\n",
    "pressure =[]\n",
    "wind_speed =[]\n",
    "wind_bearing =[]\n",
    "cloud_cover =[]\n",
    "uv_index =[]\n",
    "date =[]\n",
    "\n",
    "for i in range(-5,7):\n",
    "    try:\n",
    "        long = -117.92391\n",
    "        lat = 34.1365\n",
    "        day = datetime.today() -timedelta(days=i)\n",
    "        day = int(time.mktime(day.timetuple()))\n",
    "        url ='https://api.darksky.net/forecast/'+dskey+'/'+str(lat)+','+str(long)+','+str(day)\n",
    "        weather= requests.get(url)\n",
    "        day_length.append(weather.json()['daily']['data'][0]['sunsetTime'] - weather.json()['daily']['data'][0]['sunriseTime'])\n",
    "        try:\n",
    "            temp_high.append(weather.json()['daily']['data'][0]['temperatureHigh'])\n",
    "        except:\n",
    "            temp_high.append(weather.json()['daily']['data'][0]['temperatureMax'])\n",
    "        try:\n",
    "            temp_low.append(weather.json()['daily']['data'][0]['temperatureLow'])\n",
    "        except:\n",
    "            temp_low.append(weather.json()['daily']['data'][0]['temperatureMin'])\n",
    "        dew_point.append(weather.json()['daily']['data'][0]['dewPoint'])\n",
    "        humidity.append(weather.json()['daily']['data'][0]['humidity'])\n",
    "        pressure.append(weather.json()['daily']['data'][0]['pressure'])\n",
    "        wind_speed.append(weather.json()['daily']['data'][0]['windSpeed'])\n",
    "        wind_bearing.append(weather.json()['daily']['data'][0]['windBearing'])\n",
    "        cloud_cover.append(weather.json()['daily']['data'][0]['cloudCover'])\n",
    "        uv_index.append(weather.json()['daily']['data'][0]['uvIndex'])\n",
    "        date.append(pd.to_datetime(weather.json()['daily']['data'][0]['time'],unit='s'))\n",
    "    except:\n",
    "        print('broken at: ' +str(i))\n",
    "day_length.reverse()\n",
    "temp_high.reverse()\n",
    "temp_low.reverse()\n",
    "dew_point.reverse()\n",
    "humidity.reverse()\n",
    "pressure.reverse()\n",
    "wind_speed.reverse()\n",
    "wind_bearing.reverse()\n",
    "cloud_cover.reverse()\n",
    "uv_index.reverse()\n",
    "date.reverse()\n",
    "\n",
    "df= pd.DataFrame({\n",
    "    'Ozone': historical_ozone,\n",
    "    'day_length' : day_length,\n",
    "    'temp_high' : temp_high,\n",
    "    'temp_low' : temp_low,\n",
    "    'dew_point' : dew_point,\n",
    "    'humidity' : humidity,\n",
    "    'pressure' : pressure,\n",
    "    'wind_speed' : wind_speed,\n",
    "    'wind_bearing' : wind_bearing,\n",
    "    'cloud_cover' : cloud_cover,\n",
    "    'uv_index' :uv_index\n",
    "    \n",
    "    \n",
    "})\n",
    "## load LA scaler\n",
    "scaler = pickle.load(open('LA_all_scaled.p','rb'))\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "## load SF prediction scaler\n",
    "pred_scaler=pickle.load(open('LA_pred_scaler.p','rb'))\n",
    "\n",
    "# load dataset\n",
    "values = df.values\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "values = df.astype('float32')\n",
    "# normalize features\n",
    "scaler = pickle.load(open('scaler_all.p','rb'))\n",
    "scaled = scaler.transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 7, 5)\n",
    "# drop columns we don't want to predict\n",
    "five_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)'], axis =1).values\n",
    "five_day = five_day.reshape((five_day.shape[0], 1, five_day.shape[1]))\n",
    "five_day_lstm = keras.models.load_model('LAmodels/multi5day.h5')\n",
    "\n",
    "la_five = pred_scaler.inverse_transform(five_day_lstm.predict(five_day))[0][0]\n",
    "\n",
    "four_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "four_day = four_day.reshape((four_day.shape[0], 1, four_day.shape[1]))\n",
    "four_day_lstm = keras.models.load_model('LAmodels/multi4day.h5')\n",
    "\n",
    "la_four = pred_scaler.inverse_transform(four_day_lstm.predict(four_day))[0][0]\n",
    "\n",
    "three_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                           'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "three_day = three_day.reshape((three_day.shape[0], 1, three_day.shape[1]))\n",
    "three_day_lstm = keras.models.load_model('LAmodels/multi3day.h5')\n",
    "\n",
    "la_three = pred_scaler.inverse_transform(three_day_lstm.predict(three_day))[0][0]\n",
    "\n",
    "two_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                          'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)',\n",
    "                          'var2(t+2)','var3(t+2)','var4(t+2)','var5(t+2)','var6(t+2)',\n",
    "                          'var7(t+2)','var8(t+2)','var9(t+2)','var10(t+2)','var11(t+2)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "two_day = two_day.reshape((two_day.shape[0], 1, two_day.shape[1]))\n",
    "two_day_lstm = keras.models.load_model('LAmodels/multi2day.h5')\n",
    "\n",
    "la_two = pred_scaler.inverse_transform(two_day_lstm.predict(two_day))[0][0]\n",
    "\n",
    "one_day = reframed.drop(['var1(t)','var1(t+1)','var1(t+2)','var1(t+3)','var1(t+4)',\n",
    "                          'var2(t+4)','var3(t+4)','var4(t+4)','var5(t+4)','var6(t+4)',\n",
    "                          'var7(t+4)','var8(t+4)','var9(t+4)','var10(t+4)','var11(t+4)',\n",
    "                          'var2(t+3)','var3(t+3)','var4(t+3)','var5(t+3)','var6(t+3)',\n",
    "                          'var7(t+3)','var8(t+3)','var9(t+3)','var10(t+3)','var11(t+3)',\n",
    "                          'var2(t+2)','var3(t+2)','var4(t+2)','var5(t+2)','var6(t+2)',\n",
    "                          'var7(t+2)','var8(t+2)','var9(t+2)','var10(t+2)','var11(t+2)',\n",
    "                          'var2(t+1)','var3(t+1)','var4(t+1)','var5(t+1)','var6(t+1)',\n",
    "                          'var7(t+1)','var8(t+1)','var9(t+1)','var10(t+1)','var11(t+1)'\n",
    "                         ], axis =1).values\n",
    "\n",
    "one_day = one_day.reshape((one_day.shape[0], 1, one_day.shape[1]))\n",
    "one_day_lstm = keras.models.load_model('LAmodels/multi1day.h5')\n",
    "\n",
    "la_one = pred_scaler.inverse_transform(one_day_lstm.predict(one_day))[0][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_forecast=[la_one,la_two,la_three,la_four,la_five]\n",
    "sf_forecast=[sf_one,sf_two,sf_three,sf_four,sf_five]\n",
    "\n",
    "dates = [date[-5],date[-4],date[-3],date[-2],date[-1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LAforecast = pd.DataFrame({\n",
    "    \"Date\": dates,\n",
    "    \"Ozone(ppm)\": la_forecast\n",
    "})\n",
    "SFforecast =  pd.DataFrame({\n",
    "    \"Date\": dates,\n",
    "    \"Ozone(ppm)\":sf_forecast\n",
    "})\n",
    "\n",
    "LAforecast['Date']=LAforecast['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "SFforecast['Date']=SFforecast['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAforecast = LAforecast.round({'Ozone(ppm)':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ozone(ppm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-23</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ozone(ppm)\n",
       "0  2019-06-19       0.079\n",
       "1  2019-06-20       0.071\n",
       "2  2019-06-21       0.060\n",
       "3  2019-06-22       0.079\n",
       "4  2019-06-23       0.089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFforecast = SFforecast.round({'Ozone(ppm)':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ozone(ppm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-23</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Ozone(ppm)\n",
       "0  2019-06-19       0.020\n",
       "1  2019-06-20       0.022\n",
       "2  2019-06-21       0.023\n",
       "3  2019-06-22       0.022\n",
       "4  2019-06-23       0.023"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SFforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
